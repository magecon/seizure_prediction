{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.fftpack import fft\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_fft(data):\n",
    "    return np.fft.rfft(data, axis=1)\n",
    "\n",
    "def mat_to_pd(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return pd.DataFrame(ndata['data'], columns=ndata['channelIndices'][0])\n",
    "\n",
    "def get_fft_bins_edges(pd):\n",
    "    bins  = []\n",
    "    edges = []\n",
    "    for i in range(1, 17):\n",
    "        freq = np.abs(np.fft.fft(pd[float(str(i) + \".0\")]))\n",
    "        h = np.histogram(np.log(freq).ravel(), bins=100)\n",
    "        bins.append(h[0])\n",
    "        edges.append(h[1])\n",
    "    return np.array(bins), np.array(edges)\n",
    "\n",
    "def get_fft_bins(pd):\n",
    "    return get_fft_bins_edges(pd)[0]\n",
    "    \n",
    "def get_fft_edges(pd):\n",
    "    return get_fft_bins_edges(pd)[1]\n",
    "\n",
    "def get_high(data, return_size=50):\n",
    "    FFT = abs(scipy.fft(data))\n",
    "    return FFT[1:return_size + 1]\n",
    "\n",
    "def get_fft_peaks(data, return_size=50):\n",
    "    record_trans = np.zeros((data.shape[0], return_size*16))\n",
    "    for i, record in enumerate(data):\n",
    "        if not i % 100:\n",
    "            print(i)\n",
    "        for channel_index in range(0, 16):\n",
    "            fft = get_high(record[:, channel_index], return_size=return_size)\n",
    "            begin_idx = channel_index * return_size\n",
    "            end_idx  = begin_idx + return_size\n",
    "            record_trans[i, begin_idx : end_idx] = fft\n",
    "    return record_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_npz(column_number, name=\"\", phase=\"train\", transform_method=lambda x: x):\n",
    "    file_list = sorted(glob.glob(\"./%s_%d/*.mat\" % (phase, column_number)))\n",
    "    print(file_list)\n",
    "    X = []\n",
    "    if phase == \"train\":\n",
    "        y = []\n",
    "    for file in file_list:\n",
    "        filename = os.path.basename(file)[:-4].split(\"_\")\n",
    "        try:\n",
    "            data = mat_to_pd(file)\n",
    "            X.append(transform_method(data))\n",
    "            if phase == \"train\":\n",
    "                y.append(filename[2])\n",
    "        except Exception as e:\n",
    "            print(\"error \" + str(e))\n",
    "            continue\n",
    "\n",
    "    X_np = np.zeros((len(X), X[0].shape[0], X[0].shape[1]))\n",
    "    if phase == \"train\":\n",
    "        y_np = np.zeros((len(X), ))\n",
    "    for i in range(len(X)):\n",
    "        X_np[i] = X[i]\n",
    "        if phase == \"train\":\n",
    "            y_np[i] = y[i]\n",
    "    if phase == \"train\":\n",
    "        np.savez_compressed(file=\"./data/%s_%s_%d.npz\" \\\n",
    "                            % (phase, name, column_number), X=X_np, y=y_np)\n",
    "    else:\n",
    "        np.savez_compressed(file=\"./data/%s_%s_%d.npz\" \\\n",
    "                            % (phase, name, column_number), X=X_np)\n",
    "        \n",
    "        \n",
    "def load_data(filename):\n",
    "    Xy_dict = np.load(filename)\n",
    "    return tuple(Xy_dict.items())\n",
    "    \n",
    "    \n",
    "# transform_method is applied to data from .mat\n",
    "# elem - element from tuple, returned after transform_method\n",
    "# deprecated\n",
    "def create_csv(data, transform_method=None, elem=None, elem_length=None):\n",
    "    file_list = sorted(glob.glob(\"./train_*/*.mat\"))\n",
    "    out = open(\"./train.csv\", \"w\")\n",
    "    out.write(\"id,pid\")\n",
    "    if data is not None:\n",
    "        data_range = len(data)\n",
    "    if elem is not None:\n",
    "        data_range = elem_length*16\n",
    "    for i in range(data_range):\n",
    "        out.write(\",d\" + str(i))\n",
    "    out.write(\",result\\n\")\n",
    "    for file in file_list:\n",
    "        filename = os.path.basename(file)[:-4].split(\"_\")\n",
    "        patient_id = filename[0]\n",
    "        id = 100000*patient_id + filename[1]\n",
    "        result = filename[2]\n",
    "        try:\n",
    "            data = mat_to_pd(file)\n",
    "            if transform_method is not None:\n",
    "                data = transform_method(data)[elem]\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        out.write(str(id))\n",
    "        out.write(\",\" + str(patient_id))\n",
    "        for datum in data:\n",
    "            for element in datum:\n",
    "                out.write(\",\" + str(element))\n",
    "        out.write(\",\" + str(result))\n",
    "        out.write(\"\\n\")\n",
    "    out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to make FFT histogram bins work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv(None, get_fft_bins_edges, 0, 100)\n",
    "# save_npz(100, get_fft_bins)\n",
    "data = pd.read_csv(\"./train.csv\")\n",
    "del(data['id'])\n",
    "X = data.drop(['result', 'pid'], axis=1)\n",
    "y = data['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "X_transformed = pca.transform(X)\n",
    "plt.plot(X_transformed[np.where(y == 0)[0], 4], X_transformed[np.where(y == 0)[0], 5], 'ro')\n",
    "plt.plot(X_transformed[np.where(y == 1)[0], 4], X_transformed[np.where(y == 1)[0], 5], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking performance \n",
    "clas = RandomForestClassifier(max_depth=4, n_estimators=1000)    \n",
    "cross_val_score(clas, X, y, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting raw FFT results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = {}\n",
    "FFTX = {}\n",
    "FFTXPCA = {}\n",
    "classifiers = {}\n",
    "\n",
    "for i in range(1, 4):\n",
    "   X  = load_data(os.path.join(sys.argv[1], \"data/test_identity_%d.npz\" % i))\n",
    "   FFTX[i] = get_fft_peaks(X[0], return_size=200)\n",
    "   pca[i] = PCA()\n",
    "   FFTXPCA[i] = pca[i].fit_transform(FFTX[i])\n",
    "\n",
    "   indices = np.arange(FFTXPCA[i].shape[0])\n",
    "   np.random.shuffle(indices)\n",
    "   train_fft, test_fft = indices[:indices.shape[0]*0.8], indices[indices.shape[0]*0.8:]\n",
    "\n",
    "   classifiers[i] = XGBClassifier()\n",
    "   classifiers[i].fit(FFTXPCA[i][train_fft], y[train_fft])\n",
    "    np.savez_compressed(file=os.path.join(sys.argv[1], \"data/test_fft_simple_%d_%d.npz\" % (i, 200)), X=FFTX[i] )\n",
    "   print(classifiers[i].score(FFTXPCA[i][test_fft], y[test_fft]))\n",
    "\n",
    "pickle.dump(classifiers, open(os.path.join(sys.argv[1], \"models/2016-09-14\"), \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
