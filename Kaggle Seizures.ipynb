{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_to_pd(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return pd.DataFrame(ndata['data'], columns=ndata['channelIndices'][0])\n",
    "\n",
    "def get_fft_bins_edges(pd):\n",
    "    bins  = []\n",
    "    edges = []\n",
    "    for i in range(1, 17):\n",
    "        freq = np.abs(np.fft.fft(pd[float(str(i) + \".0\")]))\n",
    "        h = np.histogram(np.log(freq).ravel(), bins=100)\n",
    "        bins.append(h[0])\n",
    "        edges.append(h[1])\n",
    "    return np.array(bins), np.array(edges)\n",
    "\n",
    "def get_fft_bins(pd):\n",
    "    return get_fft_bins_edges(pd)[0]\n",
    "    \n",
    "def get_fft_edges(pd):\n",
    "    return get_fft_bins_edges(pd)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_npz(column_number, transform_method=lambda x: x):\n",
    "    file_list = sorted(glob.glob(\"./train_*/*.mat\"))\n",
    "    X, y = [], []\n",
    "    for file in file_list:\n",
    "        filename = os.path.basename(file)[:-4].split(\"_\")\n",
    "        try:    \n",
    "            data = mat_to_pd(file)\n",
    "            X.append(transform_method(data))\n",
    "            y.append(filename[2])\n",
    "        except Exception as e:\n",
    "            print(\"error \" + str(e))\n",
    "            continue\n",
    "    np.savez_compressed(file=\"./train.npz\", X=np.array(X), y=np.array(y))\n",
    "    \n",
    "# transform_method is applied to data from .mat\n",
    "# elem - element from tuple, returned after transform_method\n",
    "# deprecated\n",
    "def create_csv(data, transform_method=None, elem=None, elem_length=None):\n",
    "    file_list = sorted(glob.glob(\"./train_*/*.mat\"))\n",
    "    out = open(\"./train.csv\", \"w\")\n",
    "    out.write(\"id,pid\")\n",
    "    if data is not None:\n",
    "        data_range = len(data)\n",
    "    if elem is not None:\n",
    "        data_range = elem_length*16\n",
    "    for i in range(data_range):\n",
    "        out.write(\",d\" + str(i))\n",
    "    out.write(\",result\\n\")\n",
    "    for file in file_list:\n",
    "        filename = os.path.basename(file)[:-4].split(\"_\")\n",
    "        patient_id = filename[0]\n",
    "        id = 100000*patient_id + filename[1]\n",
    "        result = filename[2]\n",
    "        try:\n",
    "            data = mat_to_pd(file)\n",
    "            if transform_method is not None:\n",
    "                data = transform_method(data)[elem]\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        out.write(str(id))\n",
    "        out.write(\",\" + str(patient_id))\n",
    "        for datum in data:\n",
    "            for element in datum:\n",
    "                out.write(\",\" + str(element))\n",
    "        out.write(\",\" + str(result))\n",
    "        out.write(\"\\n\")\n",
    "    out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to make FFT histogram bins work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv(None, get_fft_bins_edges, 0, 100)\n",
    "# save_npz(100, get_fft_bins)\n",
    "data = pd.read_csv(\"./train.csv\")\n",
    "del(data['id'])\n",
    "X = data.drop(['result', 'pid'], axis=1)\n",
    "y = data['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "X_transformed = pca.transform(X)\n",
    "plt.plot(X_transformed[np.where(y == 0)[0], 4], X_transformed[np.where(y == 0)[0], 5], 'ro')\n",
    "plt.plot(X_transformed[np.where(y == 1)[0], 4], X_transformed[np.where(y == 1)[0], 5], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking performance \n",
    "clas = RandomForestClassifier(max_depth=4, n_estimators=1000)    \n",
    "cross_val_score(clas, X, y, scoring=\"roc_auc\", cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
